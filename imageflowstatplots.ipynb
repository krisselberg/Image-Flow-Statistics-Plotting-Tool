{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c6a40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# CustomDataset should return:\n",
    "# image: a PIL Image of size (H, W)\n",
    "# target: a dict containing the following fields\n",
    "# flow (FloatTensor[N, 4]): the .flo file containing \n",
    "\n",
    "class CustomDataset():\n",
    "  def __init__(self, root):\n",
    "    self.frames_dir = os.path.join('data', root, \"**/*.png\")\n",
    "    print(self.frames_dir)\n",
    "    \n",
    "    self.all_frames = []\n",
    "    for filename in glob.iglob(self.frames_dir, recursive = True):\n",
    "        self.all_frames.append(filename)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.all_frames)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    # returns the example at index \"idx\"\n",
    "    return self.all_frames[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd76a1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace data_paths and labels with your desired paths and labels\n",
    "data_paths = ['MPI-Sintel-complete/training/frames/final', 'Middlebury/training/frames']\n",
    "labels = ['Sintel', 'Middlebury']\n",
    "\n",
    "datasets = []\n",
    "for data in data_paths:\n",
    "    datasets.append(CustomDataset(data))\n",
    "\n",
    "print(len(datasets[0]))\n",
    "print(len(datasets[1]))\n",
    "print(datasets[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179dbc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luminance\n",
    "import scipy\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# returns a numpy nd array of 256 numbers, \n",
    "# each corresponding to the fraction of pixels in frames of \n",
    "# a dataset at a luminance (index)\n",
    "def get_luminance(dataset):\n",
    "    total_lum = np.zeros(256)\n",
    "    for idx in range(len(dataset)):\n",
    "        img = Image.open(dataset[idx]).convert('L')\n",
    "        total_lum += np.array(img.histogram())\n",
    "    fractional_lum = total_lum / np.sum(total_lum)\n",
    "    return fractional_lum\n",
    "    \n",
    "def plot_luminance(datasets, labels):\n",
    "    lums = []\n",
    "    for i in range(len(datasets)): \n",
    "        fractional_lum = get_luminance(datasets[i])\n",
    "        lums.append(fractional_lum)\n",
    "        plt.plot(fractional_lum, label=labels[i])\n",
    "    # KL Divergence with e as log base\n",
    "    kl = scipy.stats.entropy(lums[0], lums[1])\n",
    "    s = \"KL-D {} to {}: {:.3f}\".format(labels[0], labels[1], kl)\n",
    "    plt.text(15, 0.0150, s)\n",
    "    plt.title(\"Luminance Histogram\")\n",
    "    plt.xlabel(\"Luminance\")\n",
    "    plt.ylabel(\"Fraction of Pixels\")\n",
    "    plt.legend()\n",
    "    \n",
    "plot_luminance(datasets, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b342ac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial Power Spectra\n",
    "import math\n",
    "\n",
    "# center crop is of size 436 x 436 (change as necessary for your dataset)\n",
    "cropx, cropy = 436, 436\n",
    "total_pix = cropx * cropy\n",
    "def crop_center(img,cropx,cropy):\n",
    "    y,x = img.shape\n",
    "    startx = x//2-(cropx//2)\n",
    "    starty = y//2-(cropy//2)    \n",
    "    return img[starty:starty+cropy,startx:startx+cropx]\n",
    "\n",
    "def get_spatial_power_spectra(dataset):\n",
    "    running_ps = np.empty(cropx * cropy)\n",
    "    for frame in range(len(dataset)):\n",
    "        print(frame)\n",
    "        img = Image.open(dataset[frame]).convert(\"L\")\n",
    "        img = np.asarray(img)\n",
    "        cropped_img = np.copy(crop_center(img, cropx, cropy))\n",
    "\n",
    "        # calculate weights of Kaiser-bessel window\n",
    "        rmax = 218\n",
    "        w = np.empty(cropped_img.shape)\n",
    "        windowed_img = np.empty(cropped_img.shape)\n",
    "        for x in range(cropped_img.shape[1]):\n",
    "            for y in range(cropped_img.shape[0]):\n",
    "                r = ((x - 218)**2 + (y - 218)**2)**0.5\n",
    "                if r < rmax:\n",
    "                    w_r = 0.54 - 0.46*math.cos(math.pi*(1 - r/rmax))\n",
    "                    windowed_img[x][y] = w_r * cropped_img[x][y]\n",
    "                else:\n",
    "                    w_r = 0\n",
    "                    windowed_img[x][y] = 0\n",
    "\n",
    "                w[x][y] = w_r\n",
    "\n",
    "        # to avoid leakage in spectral transformation, we subtract the \n",
    "        # weighted mean intensity (normalizing_factor) before applying\n",
    "        # the KB window\n",
    "        normalizing_factor = np.sum(np.multiply(cropped_img, w)) / (np.sum(w))\n",
    "        normalized_img = (cropped_img - normalizing_factor) / normalizing_factor\n",
    "\n",
    "        # Fourier transform to get power spectrum\n",
    "        # used this paper to calculate: \n",
    "        # van der Schaaf, A., van Hateren, J.: Modelling the power spectra of natural images: Statistics and\n",
    "        # information. Vision Research 36 (1996) 2759 â€“ 2770\n",
    "        f = np.abs(np.fft.fft2(windowed_img))\n",
    "        ps = np.square(f)\n",
    "        ps = ps.flatten()\n",
    "        running_ps += ps\n",
    "\n",
    "    freqs = np.fft.fftfreq(ps.shape[0]) * ps.shape[0] # in x-direction\n",
    "    freqs2d = np.meshgrid(freqs, freqs)\n",
    "    freqs2d = np.sqrt(freqs2d[0]**2 + freqs2d[1]**2)\n",
    "    freqs2d = freqs2d.flatten()\n",
    "    avg_ps = running_ps / total_pix\n",
    "    return freqs2d, avgps\n",
    "\n",
    "def plot_spatial_power_spectra(datasets, labels):\n",
    "    for dataset in datasets:\n",
    "        freqs2d, avgps = get_spatial_power_spectra(dataset)\n",
    "\n",
    "        plt.plot(freqs2d, avg_ps)\n",
    "        \n",
    "plot_spatial_power_spectra(datasets, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0872167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial Derivative\n",
    "import collections\n",
    "\n",
    "# plots spatial derivative of dataset\n",
    "def get_spatial_derivatives(dataset):\n",
    "    # min difference can be (0 - 255) and max difference can be (255 - 0)\n",
    "    total_differences = collections.Counter()\n",
    "    for idx in range(len(dataset)):\n",
    "        img = np.asarray(Image.open(dataset[idx]).convert('L'), dtype='int32')\n",
    "        diff = np.reshape(np.diff(img), -1)\n",
    "        diff_counter = collections.Counter(diff)\n",
    "        total_differences.update(diff_counter)   \n",
    "        \n",
    "    totalPixelCount = sum(total_differences.values())\n",
    "    for item in total_differences: \n",
    "        total_differences[item] /= totalPixelCount\n",
    "        \n",
    "    k = scipy.stats.kurtosis(list(total_differences.values())) \n",
    "        \n",
    "    return total_differences, k\n",
    "\n",
    "def plot_spatial_derivatives(datasets, labels):\n",
    "    for i in range(len(datasets)): \n",
    "        total_differences, k = get_spatial_derivatives(datasets[i])\n",
    "        s = '{} Kurtosis = {:.2f}'.format(labels[i], k)\n",
    "        plt.text(-80, -18 - 1.5*i, s)\n",
    "        \n",
    "        # take log for better visualization\n",
    "        for item in total_differences:\n",
    "            total_differences[item] = math.log(total_differences[item])\n",
    "        plt.plot(*zip(*sorted(total_differences.items())), label=labels[i])\n",
    "        \n",
    "    plt.title(\"Spatial Derivative\")\n",
    "    plt.xlabel(\"dI/dx\")\n",
    "    plt.ylabel(\"log(fraction of pixels)\")\n",
    "    plt.legend()\n",
    "\n",
    "plot_spatial_derivatives(datasets, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4450588",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
